{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First things first. \n",
    "1. What is the difference between linear and logistic regression ?\n",
    "\n",
    "> While Linear regression is suited for predicting continuous values(House prices for example), it is not the best tool for predicting the class of an observed data point. \n",
    "\n",
    "> Basically, in order to estimate the class of the data point, we need some sort of guidance on what would be the most probable class for that datapoint. For this, we use something called as Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As we know Linear Regression finds a function that relates a continuous dependent variable y, to some predictors ( independent variables x1,x2 etc) For example, SImple Linear Regresision assumes the function of the form:\n",
    "    y = a + bx1 + cx2 + dx3 + ...\n",
    "    \n",
    "> and then find all the values of the parameters and the intercepy. We write it in vector notation as:\n",
    "    h(X) = (paramVector)T X (feature vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now, some nice details about logistic regression.\n",
    "\n",
    "> Logistic Regression is a variation of Linear Regression, useful when the observed dependent variable y is categorical and not continuous. It produces a formula that predicts the probability of a class label as a function of independent variables\n",
    "\n",
    "> Logistic regression basically fits a special S shaped curve by taking the linear regression and transforming the numeric estimate into a probability with the following function usually called as the signoid function.\n",
    "    \n",
    "    h(X) = P(Y=1|X) = sigma(parameterVector X featureVector )\n",
    "          \n",
    "         = e^(ParameterVector X featureVector)/(1+e^(ParameterVector X featureVector))\n",
    "         \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. So, in brief, Logistic Regression passes the input through the logistic/sigmoid but then treats the result as a probability.\n",
    "\n",
    "2. The objective of Logistic regression algorithm, is to find the best parameterVector for the above sigmoid equation, in such a way that the model predicts the class of each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-29 20:14:28--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/ChurnData.csv\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.193\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.193|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 36144 (35K) [text/csv]\n",
      "Saving to: ‘ChurnData.csv’\n",
      "\n",
      "ChurnData.csv       100%[===================>]  35.30K  20.5KB/s    in 1.7s    \n",
      "\n",
      "2019-10-29 20:14:32 (20.5 KB/s) - ‘ChurnData.csv’ saved [36144/36144]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Click here and press Shift+Enter\n",
    "!wget -O ChurnData.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/ChurnData.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>...</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.482</td>\n",
       "      <td>3.033</td>\n",
       "      <td>4.913</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.246</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.841</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>3.807</td>\n",
       "      <td>4.331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>3.091</td>\n",
       "      <td>4.382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "\n",
       "   longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
       "0     4.40  ...    1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n",
       "1     9.45  ...    0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n",
       "2     6.30  ...    0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n",
       "3     6.05  ...    1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n",
       "4     7.10  ...    0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n",
       "\n",
       "   lninc  custcat  churn  \n",
       "0  4.913      4.0    1.0  \n",
       "1  3.497      1.0    1.0  \n",
       "2  3.401      3.0    0.0  \n",
       "3  4.331      4.0    0.0  \n",
       "4  4.382      3.0    0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df = pd.read_csv('ChurnData.csv')\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "\n",
       "   churn  \n",
       "0      1  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df = churn_df[['tenure','age','address','income','ed','employ','equip','callcard','wireless','churn']]\n",
    "churn_df['churn'] = churn_df['churn'].astype('int')\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 10 columns):\n",
      "tenure      200 non-null float64\n",
      "age         200 non-null float64\n",
      "address     200 non-null float64\n",
      "income      200 non-null float64\n",
      "ed          200 non-null float64\n",
      "employ      200 non-null float64\n",
      "equip       200 non-null float64\n",
      "callcard    200 non-null float64\n",
      "wireless    200 non-null float64\n",
      "churn       200 non-null int64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 15.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',\n",
       "       'callcard', 'wireless', 'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.info()\n",
    "churn_df.shape\n",
    "churn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  33.,   7., 136.,   5.,   0.],\n",
       "       [ 33.,  33.,  12.,  33.,   0.,   0.],\n",
       "       [ 23.,  30.,   9.,  30.,   2.,   0.],\n",
       "       [ 38.,  35.,   5.,  76.,  10.,   1.],\n",
       "       [  7.,  35.,  14.,  80.,  15.,   0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets define X and Y for our array.\n",
    "X = np.asarray(churn_df[['tenure','age','address','income','employ','equip']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.asarray(churn_df['churn'])\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 , -0.58477841,\n",
       "        -0.85972695],\n",
       "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -1.14437497,\n",
       "        -0.85972695],\n",
       "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -0.92053635,\n",
       "        -0.85972695],\n",
       "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.02518185,\n",
       "         1.16316   ],\n",
       "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451,  0.53441472,\n",
       "        -0.85972695]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also, importantly we normalize the dataset.\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  (160, 6) (160,)\n",
      "Test set:  (40, 6) (40,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=4)\n",
    "print(\"Train set: \",X_train.shape,Y_train.shape)\n",
    "print(\"Test set: \",X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (Logistic Regression with Scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lets build our model using LogisticRegression from scikit learn package. THe version of Logistic Regression in Scikit Learn, supports regularization. Regularization is a technique used to solve the overfiiting problem in machine learning models. \n",
    "\n",
    "2. C parameter indicates inverse of Regularization Strength which must be a positive float. Smaller values indicate stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01,solver='liblinear').fit(X_train,Y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.55084393, 0.44915607],\n",
       "       [0.58894579, 0.41105421],\n",
       "       [0.54561547, 0.45438453],\n",
       "       [0.63735317, 0.36264683],\n",
       "       [0.55707784, 0.44292216],\n",
       "       [0.53654226, 0.46345774],\n",
       "       [0.53504402, 0.46495598],\n",
       "       [0.58883148, 0.41116852],\n",
       "       [0.41941097, 0.58058903],\n",
       "       [0.62707511, 0.37292489],\n",
       "       [0.59030247, 0.40969753],\n",
       "       [0.61799371, 0.38200629],\n",
       "       [0.46776399, 0.53223601],\n",
       "       [0.43580494, 0.56419506],\n",
       "       [0.64728729, 0.35271271],\n",
       "       [0.53118273, 0.46881727],\n",
       "       [0.5269285 , 0.4730715 ],\n",
       "       [0.49454596, 0.50545404],\n",
       "       [0.49927727, 0.50072273],\n",
       "       [0.53708295, 0.46291705],\n",
       "       [0.60993916, 0.39006084],\n",
       "       [0.51572106, 0.48427894],\n",
       "       [0.63298113, 0.36701887],\n",
       "       [0.52124923, 0.47875077],\n",
       "       [0.49454026, 0.50545974],\n",
       "       [0.71104927, 0.28895073],\n",
       "       [0.54195079, 0.45804921],\n",
       "       [0.51186228, 0.48813772],\n",
       "       [0.51913451, 0.48086549],\n",
       "       [0.7160412 , 0.2839588 ],\n",
       "       [0.69107615, 0.30892385],\n",
       "       [0.507595  , 0.492405  ],\n",
       "       [0.43205213, 0.56794787],\n",
       "       [0.7102381 , 0.2897619 ],\n",
       "       [0.6095058 , 0.3904942 ],\n",
       "       [0.62280643, 0.37719357],\n",
       "       [0.4075991 , 0.5924009 ],\n",
       "       [0.52397247, 0.47602753],\n",
       "       [0.6605654 , 0.3394346 ],\n",
       "       [0.50035829, 0.49964171]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "print(yhat)\n",
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:\n",
    "    1. Jaccard Index\n",
    "    2. Confusion matrix\n",
    "    3. Log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Index\n",
    "\n",
    "> This is basically defined as the size of the intersection divided by the size of the union of two label sets. If the entire set of predicted labels for a smaple match strictly with the true set of labels, then the subset accuracy is 1.0, otherwise it is 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(Y_test,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log loss\n",
    "> Now, lets try __log loss__ for evaluation. In logistic regression, the output can be the probability of customer churn is yes (or equals to 1). This probability is a value between 0 and 1.\n",
    "\n",
    "> Log loss( Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6099869851297564"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(Y_test,yhat_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  9]\n",
      " [ 2 23]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "'''\n",
    "    The function below is used to print and plot the confusion matrix.\n",
    "    Normalization can be applied by setting 'normalize' as True.\n",
    "    \n",
    "    normalization of ratings means adjusting values measured on different scales to a notionally \n",
    "    common scale, often prior to averaging.\n",
    "    \n",
    "'''\n",
    "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion Matrix',cmap = plt.cm.Blues):\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float')/cm.sum(axis=1) [:, np.newaxis]\n",
    "        print(\"Normalized Confusion Matrix\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Confusion matrix without normalization\")\n",
    "        \n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm,interpolation='nearest',cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    \n",
    "    plt.xticks(tick_marks,classes,rotation=45)\n",
    "    plt.yticks(tick_marks,classes)\n",
    "    \n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "print(confusion_matrix(Y_test,yhat,labels=[1,0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix without normalization\n",
      "[[ 6  9]\n",
      " [ 2 23]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In above, 6 and 23 represent the correctly predicted ones.\n",
    "cnf_matrix = confusion_matrix(Y_test,yhat,labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, looking at the first row. The first row is for customers whose actual churn value in the test set is 1. As we can see out of 40 customers, the churn of 15 of them is 1. And out out of these 15, only 6 are predicted as correct.\n",
    "\n",
    "> The classifier did a pretty good job while classifyng the values with churn as 0.\n",
    "\n",
    "> A good thing about confusion_matrix is that, it shows the models ability to correctly predict or separate the classes.\n",
    "Here, we will have true positives, flase positives, false negative and true negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81        25\n",
      "           1       0.75      0.40      0.52        15\n",
      "\n",
      "   micro avg       0.72      0.72      0.73        40\n",
      "   macro avg       0.73      0.66      0.66        40\n",
      "weighted avg       0.73      0.72      0.70        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Precision is a measure of the accuracy provided that a class label has been predicted. precision = TP/(TP+FP)\n",
    "\n",
    "> Recall is true positive rate. It is defined as Recall = TP/(TP+FN)\n",
    "\n",
    "> F1-Score: THe F1 rate is the harmonic average of the precision and recall, where an F1 Score reaches its best value at 1(perfect precision and recall) and worst is 0.\n",
    "\n",
    "> Finally, the average accuarcy of the classifier is the average of F1-Score for both labels "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
